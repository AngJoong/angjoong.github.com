---
layout: post
title:  "3. RDD로 프로그래밍하기"
date:   2016-10-05 20:38:00 +0000
description: 스파크의 모든 작업은 RDD를 만들거나, 변경하는것이다.
tags: ['Spark']
author: "AngJoong"
---

# 1. RDD 기초
분산 되어 있는 변경 불가능한 객체 모음이다.  
클러스터의 서로 다른 노드에서 연산하도록 여러 개의 파티션(Partition)으로 나뉜다.  
사용자 정의 클래스를 포함, 파이썬, 자바, 스칼라의 어떤 타입의 객체든 가질 수 있다.  
외부 데이터세트를 로드하거나 드라이버 프로그램에서 객체 컬렉션을 분산시켜 만들 수 있다.  

# 2. RDD 생성하기

1. 드라이버 프로그램에서 RDD 생성
2. 외부 스토리지에서 RDD 생성

## 2.1 드라이버프 로그램에서 RDD 생성

```java
JavaRDD<String> lines = sc.parallelize(Arrays.asList(“pandas”, “i like pandas”));
```

## 2.2 외부 스토리지에서 RDD 생성
* 일반적인 방법

```java
JavaRDD<String> lines = sc.textFile(“/path/to/READMD.md"));
```

## 3. RDD 연산

### 3.1 여유로운 방식 (lazy evaluation)
데이터를 처리할 때마다 파일의 모든 내용을 로드하게 되면 스토리지 낭비 발생  
모든 트랜스포메이션끼리의 연계를 파악후 처음 액션을 사용하는 시점에서 결과 도출에 필요한 데이터만을 연산  

### 3.2 트랜스포메이션(Transformation)
존재하는 RDD에서 새로운 RDD를 만들어 낸다.(inputRDD 재사용 가능)  
RDD간의 관계 그래프(lineage graph)를 통해 RDD를 재 연산하거나 복구한다.  

```java
JavaRDD<String> inputRDD = sc.textFile(“log.txt"));
// inputRDD -> errorRDD
JavaRDD<String> errorRDD = inputRDD.filter(
     new Function<String. Boolean>() {
         public boolean call(String x) {return x.contains(“error”);}
     }
);
```

### 3.3 액션(action)
RDD를 기초로 결과 값을 계산하며 그 값을 드라이버 프로그램에 되돌려주거나 외부 스토리지(ex: HDFS)에 저장한다.  
액션이 실행될 때마다 매번 새로 연산을 한다.(중간 결과를 저장하기 위해 .persist() 사용)  
RDD외 타입 반환  

```java

System.out.println(“Input had “ + badLinesRDD.count() + “ concerning lines”);

System.out.println(“Here are 10 examples:”);

for(String line: badLinesRDD.take(10)) {

     System.out.println(line);

}

```
















###### <예제 8-1> SparkConf 설정
```java
// conf 생성
SparkConf conf = new SparkConf();
conf.set("spark.app.name", "My Spark App"); // .setAppName("My Spark App")
conf.set("spark.master", "local[4]"); // .setMaster("local[4]")
conf.set("spark.ui.port", "36000");

JavaSparkContext sc = new JavaSparkContext(conf);
```

## 1.2 spark-submit에서 설정
애플리케이션을 **실행할때 동적으로 설정** 값을 줄 수 있다.  
spark-submit 도구는 내장된 가장 **일반적인 스파크 설정** 및 **범용적인 플래그**(`--conf`) 모두 지원한다.  
설정값을 **파일에서 읽는 것**도 지원한다. 기본 설정 파일은 `conf/spark-defaults.conf`이다.  

###### <예제 8-2> spark-submit 설정
```bash
# 1. 플래그를 사용하여 설정
$ bin/spark-submit \
  --class com.example.MyApp \
  --master local[4] \
  --name "My Spark App" \
  --conf spark.ui.port=36000 \
  myApp.jar

# 2. 파일을 읽어 설정
$ bin/spark-submit \
  --class com.example.MyApp \
  --properties-file my-config.conf \ #설정 파일 경로 설정
  myApp.jar
```

## 1.3 설정 우선 순위
동일한 설정값이 여러곳에서 사용되는 경우 스카프 설정 우선순위를 따른다.

* 사용자 코드의 SparkConf -> spark-submit 플레그 -> spark-submit 파일 -> 기본 값


# 2. 실행 구성 - 작업, 태스크, 작업 단계
스파크를 최적화하고 디버깅하기 위해서 시스템의 내부 설계를 이해 한다.

###### <예제 8-3> 로그 레벨 카운팅
``` scala
// 입력 파일 읽기
scala> val input = sc.textFile("input.txt"); // input.txt - line ex> INFO back to normal messages
// 빈라인 제거 및 단어 분리
scala> val tokenized = input.
		filter(line => line.size > 0).
        map(line => line.split(" "))
// 첫번째 단어(로그 레벨) 추출 및 카운팅
scala> val counts = tokenized.
		map(words => (words(0), 1)).
        reduceByKey{ (a, b) => a + b}

scala> counts.collect()
```

## 2.1 가계도(Lineage graph) - DAG
RDD는 내부적으로 정의된 **가계도**라고 불리는 지향성 비순환 그래프(DAG, Directed Acyclic Graph) 갖는다.  
각 RDD들은 부모 RDD를 가리키는 포인터를 가지며 이를 활용해 모든 조상 RDD를 추적할 수 있다.

###### <예제 8-4> RDD 가계도 시각화
```scala
scala> input.toDebugString
res85: String =
(2) input.text MappedRDD[292] at textFile at <console>:13
 -  input.text HadoopRDD[291] at textFile at <console>:13

scala> counts.toDebugString
res85: String =
(2) ShuffledRDD[296] at reduceByKey at <soncole>:17
 +-(2) MappedRDD[295] at map at <console>:17
    |  FilteredRDD[294] at filter at <console>:15
    |  MappedRDD[293] at map at <console>:15
    |  input.text MappedRDD[292] at textFile at <console>:13
    |  input.text HadoopRDD[291] at textFile at <console>:13
```

위 가계도를 통해 어떤 함수가 어떤 RDD를 만들었는지 확인할 수 있다.  

* `.textFile()` -> HadoopRDD -> MappedRDD

여러 개의 RDD를 하나의 작업 단계(Stage)로 합치는 경우 존재  

* 파이프 라이닝: RDD들이 데이터 이동 없이 부모에서부터 연산이 가능할때 발생
* 건너뛰기(short-circuit): 캐싱된 부분은 생략하고 영속화 되어 있는 RDD기준으로 연산한다.
* 이미 이전에 실행된 셔플링으로 인해 RDD의 데이터가 남아 있는 경우

동일한 들여쓰기 단계에 따라 물리 단계에서 합쳐지는 것을 나타낸다.  

1. counts RDD연산시 단 2단계의 물리적 단계 존재(들여쓰기)
2. filter()와 map()등 여러 연산이 순서대로 이루어지는 파이프라이닝



###### <예제 8-5> RDD 모으기
```scala
scala> counts.collect()
res86: Array[(String, Int)] = Array((ERROR,1), (INFO,4), (WARN,2))
```
스파크의 스케줄러는 연산한 마지막 RDD`(counts)`부터 가계도를 역으로 추적해 물리적 실행계획을 만든다.  
**<예제 8-5>**의 `collect()`를 호출할때 물리적 실행계획을 통해 RDD의 모든 파티션들이 실체화되고 드라이버 프로그램으로 전송된다.  

## 2.2 작업 단계(Stage)
액션을 호출할 때마다 하나 이상의 작업 단계로 구성된 작업(Job)을 만든다.  
물리적 작업 단계는 실행되는 데이터 파티션은 서로 다르지만 같은 일을 수행하는 태스크(Task)들을 실행시킨다.  

## 2.3 태스크(Task) 수행 순서

1. 데이터를 가져온다.
	* 저장 장치: RDD가 입력 RDD인 경우
	* 존재하는 RDD: 캐시된 데이터에 대해 작업 단계가 수행 될 경우
	* 셔플 결과물
2. RDD 연산들을 수행한다.
3. 결과를 셔플, 외부 저장 장치에 쓰거나 드라이버에 되돌려 준다.
